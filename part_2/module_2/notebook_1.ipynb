{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тетрадь 3: Оценка точности моделей классификации\n",
    "\n",
    "В настоящей тетради мы обсудим, как оценивать точность (или предсказательную способность) модели\n",
    "классификации. Также научимся самостоятельно определять функции для этих целей и пользоваться ими.\n",
    "\n",
    "# Содержание\n",
    "\n",
    "- [Теория](#Теория)\n",
    "- [Примеры](#Примеры)\n",
    "- [Задания](#Задания)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория\n",
    "\n",
    "### Метрики\n",
    "\n",
    "В контексте машинного обучения (ML) и искусственного интеллекта (AI) **метрики** - это\n",
    "количественные показатели, используемые для оценки производительности, результативности и качества\n",
    "моделей. Эти показатели помогут нам понять, насколько хорошо модель справляется с поставленной\n",
    "задачей. В зависимости от типа решаемой задачи используются различные показатели (например,\n",
    "классификация, регрессия, кластеризация).\n",
    "\n",
    "### Показатели классификации\n",
    "Классификация - это распространенная задача в ML, целью которой является прогнозирование категориальной метки для заданных входных данных. Общие показатели для оценки моделей классификации включают:\n",
    "\n",
    "#### Точность (Accuracy)\n",
    "Точность суть доля правильно предсказанных экземпляров из общего числа экземпляров. Она\n",
    "определяется как:\n",
    "\n",
    "$$ \\textrm{Acc}(Y_n, Y_N) = \\frac{Y_n}{Y_N}, $$\n",
    "где:\n",
    "* $Y_n$ — количество правильных предсказаний;\n",
    "* $Y_N$ — общее количство предсказаний.\n",
    "\n",
    "Точность очевидна, но может вводить в заблуждение, особенно в несбалансированных наборах данных,\n",
    "где доминирует один класс.\n",
    "\n",
    "#### Матрица ошибок (Confusion Matrix)\n",
    "Матрица ошибок — это таблица, которая суммирует эффективность классификационной модели, показывая\n",
    "количество истинно положительных (TP), истинно отрицательных (TN)\n",
    "ложноположительных (FP) и ложноотрицательных (FN) прогнозов. Из этой матрицы\n",
    "могут быть получены другие показатели. В качестве примера рассмотрим две иллюстрации матрицы ошибок:\n",
    "элементарную и сложную (в которой классов больше двух). Вот элементарная матрица ошибок, где всего\n",
    "два класса (1 и 0):\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../images/confusion_matrix_simple.png\" alt=\"Train Test Valid Split\" width=512 height=256>\n",
    "</div>\n",
    "\n",
    "В таблице слева, мы видим, что:\n",
    "* TP (True Positive) — Значение класса суть 0 и предсказание модели есть 0; \n",
    "* TN (True Negative) — Значение класса есть 1 и предсказание модели суть 1;\n",
    "* FP (False Positive) — Значение класса суть 1, а предсказание модели есть 0;\n",
    "* FN (False Negative) — Значение класса есть 0, а предсказание модели суть 1.\n",
    "\n",
    "Таким образом, cправа уже матрица, в которой 3 TP, 5 TN, 1 FP и 2 FN.\n",
    "\n",
    "#### Прецизионность (Precision)\n",
    "Прецизионность есть доля истинно положительных прогнозов из всех положительных прогнозов (как\n",
    "истинных, так и ложноположительных). Определяется как:\n",
    "$$ \\textrm{Prec} = \\frac{\\textrm{TP}}{\\textrm{TP} + \\textrm{FP}} $$\n",
    "Прецизионность полезна, когда высока вероятность ложных срабатываний.\n",
    "\n",
    "#### Отзывчивость (Recall)\n",
    "Отзывчивость (чувствительность или Истинно положительный показатель) — это доля истинно\n",
    "положительных прогнозов из всех реальных положительных примеров. Определяется как:\n",
    "$$ \\textrm{Rec} = \\frac{\\textrm{TP}}{\\textrm{TP} + \\textrm{FN}} $$\n",
    "Отзывчивость важна, когда стоимость ложноотрицательных результатов высока.\n",
    "\n",
    "#### Специфичность (Specificity)\n",
    "Показатель специфичности особенно полезен, когда высока вероятность ложных срабатываний (ошибочной\n",
    "классификации отрицательного экземпляра как положительного). Формула для спцифичности выглядит так:\n",
    "$$ \\textrm{Spec} = \\frac{\\textrm{TN}}{\\textrm{TN} + \\textrm{FP}} $$\n",
    "Специфичность является важнейшим показателем в сценариях, где класс отрицательных результатов имеет\n",
    "особое значение, и минимизация ложных срабатываний имеет решающее значение.\n",
    "\n",
    "#### Показатель F1 (F1 Score)\n",
    "Показатель F1 суть среднее гармоническое значение прецизионности и отзывчивости. Он определяется\n",
    "как:\n",
    "$$\n",
    "\\textrm{F}_1 = 2 \\times \\frac{\\textrm{Prec} \\times \\textrm{Rec}}{\\textrm{Prec} + \\textrm{Rec}}\n",
    "$$\n",
    "Оценка F1 будет полезна, если мы захотим сбалансировать прецизионность и отзывчивость.\n",
    "\n",
    "#### Кривая ROC\n",
    "Кривая ROC (кривая рабочих характеристик приемника) есть график, иллюстрирующий диагностические\n",
    "возможности системы бинарного классификатора при изменении ее порога распознавания. Кривая строится\n",
    "путем сопоставления истинно положительной частоты (TPR) и ложноположительной частоты (FPR) при\n",
    "различных пороговых значениях.\n",
    "\n",
    "```shell\n",
    "TODO: ROC graph illustration\n",
    "```\n",
    "\n",
    "#### AUC\n",
    "Площадь под кривой ROC (тут уже ничего пояснять не нужно). Более высокий показатель AUC указывает\n",
    "на налучшую производительность модели, при изменении каждой из пороговых настроек.\n",
    "\n",
    "#### Перекрестная проверка (Cross Validation) \n",
    "Перекрёстный метод оценки того, насколько модель обобщается для независимого набора данных. Он\n",
    "включает в себя разбиение данных на несколько групп и обучение/тестирование модели на разных\n",
    "подмножествах.\n",
    "\n",
    "#### Кривые обучения (Learning Curves)\n",
    "Графики, показывающие производительность модели (например, точность, потери) в зависимости от\n",
    "размера обучающей выборки. Они помогают диагностировать чрезмерную или недостаточную адаптацию. Этот\n",
    "показатель также является одним из наиболее наглядных, так как позволяет быстро оценить качество\n",
    "модели за счёт широкого ассортимента средств визуализации.\n",
    "\n",
    "#### Сложность модели (Model Complexity)\n",
    "Такие показатели, как количество параметров, вычислительная сложность и размер модели, могут\n",
    "использоваться для оценки эффективности и масштабируемости модели.\n",
    "\n",
    "Рассмотрим теперь на примерах применения некоторых из вышеописанных метрик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры\n",
    "\n",
    "### Точность (Accuracy)\n",
    "\n",
    "Метод оценки точности модели довольно тривиален. Нам лишь нужно поделить количество правильных\n",
    "предсказаний на общее количество предсказаний. Сделать это можно следующим образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "def compute_accuracy(actual: ndarray, predicted: ndarray) -> float:\n",
    "    accuracy = np.sum(predicted == actual) / len(actual)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы нам было, что оценивать, сгенерируем два массива. Один из них будет «действительным», а\n",
    "второй — «предсказанным». А затем применим нашу функцию вычисления точности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "y_actual, y_pred = (\n",
    "    np.array([random.randint(0, 1) for _ in range(10)]),\n",
    "    np.array([random.randint(0, 1) for _ in range(10)]),\n",
    ")\n",
    "accuracy = compute_accuracy(y_actual, y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это было довольно просто. Рассмотрим теперь чуть более сложный пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1.]\n",
      " [0. 2. 1.]\n",
      " [3. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "\n",
    "IndicesMap = Dict[Any, int]\n",
    "ConfusionMatrix = Tuple[ndarray, IndicesMap]\n",
    "\n",
    "\n",
    "def compute_confusion_matrix(\n",
    "    actual: ndarray,\n",
    "    predicted: ndarray,\n",
    "    indices_map: Optional[IndicesMap] = None,\n",
    ") -> ConfusionMatrix:\n",
    "\n",
    "    # We need to map all the outcomes to integers to place them as rows and\n",
    "    # columns in the confusion matrix\n",
    "    def _map_to_integers(array, intmap):\n",
    "        for i, _ in enumerate(array):\n",
    "            array[i] = intmap[array[i]]\n",
    "        return array\n",
    "\n",
    "    # Then the arrays of actual and predicted values must be converted into\n",
    "    # lists, so that we can treat those values as a common Python data structure\n",
    "    actual_list, predicted_list = (\n",
    "        list(chain.from_iterable(actual.tolist())),\n",
    "        list(chain.from_iterable(predicted.tolist())),\n",
    "    )\n",
    "    concatenated = actual_list + predicted_list\n",
    "    n_features = len(set(concatenated))\n",
    "    if indices_map is None:\n",
    "        # If there is no indicies map provided, we create a default one\n",
    "        indices_map = {\n",
    "            key: val for key, val in zip(set(concatenated), range(n_features))\n",
    "        }\n",
    "\n",
    "    confusion_matrix = np.zeros((n_features, n_features))\n",
    "    mapped_actual, mapped_predicted = (\n",
    "        _map_to_integers(actual_list, indices_map),\n",
    "        _map_to_integers(predicted_list, indices_map),\n",
    "    )\n",
    "    # Finally, the ocurrances of each value get summed up in the corresponding\n",
    "    # matrix cells\n",
    "    for a, p in zip(mapped_actual, mapped_predicted):\n",
    "        confusion_matrix[a, p] += 1\n",
    "    confusion_matrix_with_map: ConfusionMatrix = confusion_matrix, indices_map\n",
    "\n",
    "    return confusion_matrix_with_map\n",
    "\n",
    "\n",
    "y_actual, y_pred = (\n",
    "    np.array([random.randint(0, 2) for _ in range(10)]).reshape((-1, 1)),\n",
    "    np.array([random.randint(0, 2) for _ in range(10)]).reshape((-1, 1)),\n",
    ")\n",
    "confusion_matrix, _ = compute_confusion_matrix(y_actual, y_pred)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы имеем некоторое представление о метриках для моделей классификации и реализующих\n",
    "их функциях, приступим к выполнению задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Рассмотрев примеры выше, можно понять принцип постоения данных функций оценивания. Таким образом,\n",
    "в качестве задания теперь дополните следующую функцию для вычисления чувствительности и\n",
    "специфичности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sensitivities_and_specificities(\n",
    "    actual: ndarray, predicted: ndarray, as_array: bool = True\n",
    ") -> Any:\n",
    "    # Obtain the confusion matrix and the indicies map to compute true\n",
    "    # positives, true negatives, false positives and false negatives\n",
    "    confusion_matrix, indices_map = compute_confusion_matrix(actual, predicted)\n",
    "    n_features = len(indices_map)\n",
    "\n",
    "    sensitivities, specificities = (list(), list())\n",
    "    for i in range(n_features):\n",
    "        # Compute sensetivities\n",
    "        true_positives = ...\n",
    "        false_negatives = ...\n",
    "        sensitivity = true_positives / (true_positives + false_negatives)\n",
    "        sensitivities.append(sensitivity)\n",
    "\n",
    "        # Compute specificities\n",
    "        upper_left = ...\n",
    "        upper_right = ...\n",
    "        lower_left = ...\n",
    "        lower_right = ...\n",
    "        true_negatives = np.sum(\n",
    "            (upper_left, upper_right, lower_left, lower_right)\n",
    "        )\n",
    "        false_positives = np.sum(confusion_matrix[i])\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "        specificities.append(specificity)\n",
    "\n",
    "    # In case we do not want to recieve the resulting data as a NumPy array,\n",
    "    # the data must be serialized as a Python data structure\n",
    "    if not as_array:\n",
    "        features_names = list(indices_map.keys())\n",
    "        keys = [\"sensitivities\", \"specificities\"]\n",
    "        metrics = sensitivities, specificities\n",
    "        sensitivities_and_specificities = dict.fromkeys(keys)\n",
    "        for outer_key, metric in zip(keys, metrics):\n",
    "            sensitivities_and_specificities[outer_key] = {\n",
    "                key: val for key, val in zip(features_names, metric)\n",
    "            }\n",
    "        return sensitivities_and_specificities\n",
    "\n",
    "    # Otherwise, we return NumPy arrays as is\n",
    "    sensitivities_and_specificities = np.array([sensitivities, specificities])\n",
    "    return sensitivities_and_specificities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как восполните пропуски в дефиниции функции выше, запустите следующую ячейку, чтобы\n",
    "проверить правильность решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'ellipsis' and 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m y_actual, y_pred \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m     np\u001b[38;5;241m.\u001b[39marray([random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     np\u001b[38;5;241m.\u001b[39marray([random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m sensitivities_and_specificities \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_sensitivities_and_specificities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_actual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(sensitivities_and_specificities)\n",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m, in \u001b[0;36mcompute_sensitivities_and_specificities\u001b[1;34m(actual, predicted, as_array)\u001b[0m\n\u001b[0;32m     12\u001b[0m true_positives \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m     13\u001b[0m false_negatives \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m---> 14\u001b[0m sensitivity \u001b[38;5;241m=\u001b[39m true_positives \u001b[38;5;241m/\u001b[39m (\u001b[43mtrue_positives\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfalse_negatives\u001b[49m)\n\u001b[0;32m     15\u001b[0m sensitivities\u001b[38;5;241m.\u001b[39mappend(sensitivity)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute specificities\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'ellipsis' and 'ellipsis'"
     ]
    }
   ],
   "source": [
    "y_actual, y_pred = (\n",
    "    np.array([random.randint(0, 2) for _ in range(10)]).reshape((-1, 1)),\n",
    "    np.array([random.randint(0, 2) for _ in range(10)]).reshape((-1, 1)),\n",
    ")\n",
    "sensitivities_and_specificities = compute_sensitivities_and_specificities(\n",
    "    y_actual, y_pred\n",
    ")\n",
    "\n",
    "print(sensitivities_and_specificities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же можете попробовать реализовать другие функции для вычисления метрик, упомянутых в\n",
    "[теории](#Теория)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Показатели являются важными инструментами в области ОД и искусственного интеллекта для оценки эффективности моделей, руководства при выборе моделей и обеспечения того, чтобы модели хорошо обобщались на новые данные. Выбор показателя зависит от конкретной проблемы, характера данных и желаемых результатов. Понимание этих показателей позволяет практикам принимать обоснованные решения и повышать эффективность своих моделей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratches",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
