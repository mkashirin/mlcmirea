{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тетрадь 2: Преобразователи данных\n",
    "\n",
    "Предметом изучения в данной тетради являются преобразователи данных. Мы разберём, что они \n",
    "из себя представляют, как они устроены и для чего нужны.\n",
    "\n",
    "## Содержание\n",
    "\n",
    "- [Теория](#Теория)\n",
    "...\n",
    "\n",
    "Приступим теперь непосредственно к изучению материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория\n",
    "\n",
    "### Преобразование и предварительная обработка данных\n",
    "\n",
    "**Предварительная обработка данных** (Data Preprocessing) в машинном обучении — это набор методов и \n",
    "техник, которые применяются к исходным данным перед их использованием для обучения модели. Цель \n",
    "предварительной обработки — подготовить данные к анализу, улучшить их качество и сделать их более \n",
    "пригодными для обучения моделей машинного обучения.\n",
    "\n",
    "Вообще, существует множество различных этапов предварительной обработки данных. Однако в контексте \n",
    "данного курса мы будем относить всякие манипуляции, будь то очистка, сокращение размерности или \n",
    "форматирование, к преобразованиям данных. Отсюда **преобразователи данных** — программные интерфейсы \n",
    "(в основном классы), которые переводят данные из одного состояние в другое.\n",
    "\n",
    "Проиллюстрируем такой этап предобработки, как дополнение данных. Суть дополнения в том, что \n",
    "информация, которую вы где-либо раздобыли для анализа далеко не всегда является полной (например, в \n",
    "таблице присутствуют пустые поля). Ниже представлена диаграмма, которая схематично описывает эффект \n",
    "применения так называемого `Imputer`'а к данным с пропусками.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../images/imputer_scheme.png\" alt=\"Imputer Scheme\" width=512 height=256>\n",
    "</div>\n",
    "\n",
    "Как можно заметить на диаграмме, в первой таблице (Raw Data) присутствовали некоторые пропущенные \n",
    "поля. После пропуска данных через `Imputer` всё стало на свои места. Столбцы были заполнены по \n",
    "соответствующим закономерностям.\n",
    "\n",
    "### Некоторые этапы предварительной обработки данных\n",
    "\n",
    "Возвращась к разнообразию этапов предварительной обработки данных, пречислим некоторые из них: \n",
    "\n",
    "- **Разделение:** тренировочный/тестовый/валидационный набор; кросс-валидация.\n",
    "\n",
    "- **Очистка:** удаление дубликатов; обработка пропущенных значений; удаление шума.\n",
    "\n",
    "- **Масштабирование:** нормализация/Стандартизация (например, Min-Max нормализация, \n",
    "Z-масштабирование); логарифмирование/экспоненцирование.\n",
    "\n",
    "- **Кодирование:** бинарное кодирование (One-Hot Encoding); лэйбл-кодирование (Label Encoding).\n",
    "\n",
    "- **Уменьшение Размерности:** PCA (Principal Component Analysis); t-SNE (t-distributed Stochastic \n",
    "Neighbor Embedding); LDA (Linear Discriminant Analysis).\n",
    "\n",
    "### Порядок выполнения этапов предварительной обработки\n",
    "\n",
    "Очень важно помнить, что порядок выполнения этих этапов действительно имеет огромное значение.\n",
    "Сначала выполняется разделение данных, затем очистка, а потом уже всё остальное. Также далее мы \n",
    "обсудим не менее значимый нюанс касаемо применения преобразователей к отдельным наборам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры\n",
    "\n",
    "Рассмотрим теперь несколько упрощённых и один полный пример преобразователей данных. Начнём с \n",
    "более простых функций, а далее продемонстрируем полноценный класс. В качетве преобразования для \n",
    "примера возьмём Z-масштабирование. Формула для этой операции выглядит следующим образом:\n",
    "\n",
    "$$Z(X) = \\frac{X - \\textrm{Mean}(X)}{\\textrm{Std}(X)},$$\n",
    "\n",
    "где\n",
    "- $X$ — множество всех точек данных признака;\n",
    "- $\\textrm{Mean}(X)$ — среднее по $X$;\n",
    "- $\\textrm{Std}(X)$ — стандартное отклонение по $X$.\n",
    "\n",
    "Запрограммируем функцию для Z-масштабирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "def z_scale(data: ndarray) -> ndarray:\n",
    "    scaled = (data - np.mean(data)) / np.std(data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь представим некоторый случайный набор данных и применим к нему нашу функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "[[-0.64  -0.555 -0.101  0.899]\n",
      " [-1.279 -0.949  0.066 -2.702]\n",
      " [ 0.425 -1.491 -1.077  1.915]\n",
      " [-0.956  0.737 -0.307  0.949]\n",
      " [-0.456  0.661  1.113  0.674]\n",
      " [-0.916  1.174  0.462  1.318]\n",
      " [-0.704 -1.318  0.706  0.032]\n",
      " [ 1.61  -0.799  0.934 -1.414]\n",
      " [-0.196  0.475  1.361 -0.563]\n",
      " [ 0.413 -0.166  0.948 -0.142]]\n",
      "\n",
      "After scaling:\n",
      "[[-0.644 -0.559 -0.105  0.896]\n",
      " [-1.283 -0.953  0.063 -2.707]\n",
      " [ 0.422 -1.495 -1.081  1.913]\n",
      " [-0.96   0.734 -0.311  0.946]\n",
      " [-0.46   0.658  1.11   0.671]\n",
      " [-0.92   1.171  0.459  1.315]\n",
      " [-0.708 -1.322  0.703  0.028]\n",
      " [ 1.607 -0.803  0.931 -1.418]\n",
      " [-0.2    0.472  1.358 -0.567]\n",
      " [ 0.41  -0.17   0.945 -0.146]]\n"
     ]
    }
   ],
   "source": [
    "(size, round_to) = ((10, 4), 3)\n",
    "selection = np.round(np.random.standard_normal(size), round_to)\n",
    "scaled = np.round(z_scale(selection), round_to)\n",
    "\n",
    "print(f\"Before scaling:\\n{selection}\\n\\nAfter scaling:\\n{scaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, всё работает отлично! Однако, есть нюанс, о котором было упомянуто в конце теоретического \n",
    "раздела, и сейчас мы его обусдим.\n",
    "\n",
    "Итак, представьте, что вы обучаете модель на тренировочных данных. Вы готовите её к взаимодействию \n",
    "с информацией, которую она ещё не видела. Но во время преобразования данных вы применяете инструмент \n",
    "трансформации к каждому из наборов (тренировочному и тестовому) по отдельности. То есть та же функция \n",
    "`z_scale()` принимает во внимание характеристики тестового набора данных при его масштабировании. \n",
    "Теперь представим, что тестового набора нет. Вам только предстоит его получить и обработать. \n",
    "Получается, для преобразования тестового набора данных нам нужно заглянуть в будущее!\n",
    "\n",
    "Многие начинающие часто совершают эту ошибку. Новички трансформируют тестовые данные, пользуясь их \n",
    "характеристиками. Хоть это и явное противоречие, часто его никто не замечает. Так что же делать с \n",
    "этим противоречием? \n",
    "\n",
    "Для решения этой проблемы нам понадобится хранить параметры тренировочных данных (минимум, максимум, \n",
    "среднее, медиану, стандартное отклонение и т.п.) и использовать их для преобразований тестовых. \n",
    "Рассмотрим конкретную реализацию.\n",
    "\n",
    "Для начала зададим интерфейс преобразователя в той форме, в которой нам будет удобно им пользоваться.\n",
    "За основу возьмём те же классы-трансформеры из библиотеки Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "class BasePreprocessor(ABC):\n",
    "    \"\"\"The Base Preprocessor class is an abstract base class for preprocessor\n",
    "    implementations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        self.copy = copy\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, x) -> None:\n",
    "        \"\"\"Fit the preprocessor to the provided features.\"\"\"\n",
    "        message = \"Every preprocessor must implement the `fit()` method.\"\n",
    "        raise NotImplementedError(message)\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, x) -> Any:\n",
    "        \"\"\"Transform the input features.\"\"\"\n",
    "        message = (\n",
    "            \"Every preprocessor must implement the `transform()` method.\"\n",
    "        )\n",
    "        raise NotImplementedError(message)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_values_masks(array: ndarray) -> Tuple[bool, bool]:\n",
    "        non_zero_values_mask = (array != 0)\n",
    "        zero_values_mask = ~non_zero_values_mask\n",
    "        return non_zero_values_mask, zero_values_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, это [абстрактный базовый класс](https://docs.python.org/3/library/abc.html). При \n",
    "инициализации мы задаём параметр `copy`, который нам пригодится в дальнейшем. Главное — у класса \n",
    "`BasePreprocessor` есть методы `fit()` и `transform()`. Первый отвечает за хранение характеристик \n",
    "данных, а второй за применение транформации с учётом самых характеристик. Есть также защищённый \n",
    "метод `_get_values_masks()`. О нём мы тоже поговорим чуть позже.\n",
    "\n",
    "Рассмотрим теперь конкретную реализаицю Z-масштабирующего преобразователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScalingPreprocessor(BasePreprocessor):\n",
    "    \"\"\"Z-Scaling Preprocessor class for features standard scaling.\"\"\"\n",
    "\n",
    "    def __init__(self, copy: bool = True):\n",
    "        super().__init__(copy)\n",
    "        self.means: ndarray\n",
    "        self.stds: ndarray\n",
    "\n",
    "    def fit(self, x: ndarray) -> None:\n",
    "        \"\"\"Fit the preprocessor to the input x and computes the mean and\n",
    "        standard deviation for each feature.\n",
    "\n",
    "        :parameter x: The features to fit the preprocessor and compute the\n",
    "        statistics.\n",
    "            :type x: :class:`ndarray`\n",
    "        \"\"\"\n",
    "        self.means = np.nanmean(x, axis=0)\n",
    "        self.stds = np.nanstd(x, axis=0)\n",
    "\n",
    "    def transform(self, x: ndarray) -> ndarray:\n",
    "        \"\"\"Transform the input features and standard scale the data according\n",
    "        to the computed mean and standard deviation.\n",
    "\n",
    "        :parameter x: Features to scale and transform.\n",
    "            :type x: :class:`ndarray`\n",
    "\n",
    "        :return: Standard scaled features.\n",
    "            :rtype: :class:`ndarray`\n",
    "        \"\"\"\n",
    "        if self.copy:\n",
    "            x = x.copy()\n",
    "\n",
    "        (nonzero_std_mask, zero_std_mask) = self._get_values_masks(self.stds)\n",
    "        (nonzero_mean_mask, _) = self._get_values_masks(self.means)\n",
    "        x[:, zero_std_mask] = 0\n",
    "        \n",
    "        x[:, nonzero_std_mask] = (\n",
    "            x[:, nonzero_std_mask] - self.means[nonzero_mean_mask]\n",
    "        ) / self.stds[nonzero_std_mask]\n",
    "        return x\n",
    "\n",
    "    def fit_transform(self, x) -> ndarray:\n",
    "        \"\"\"Fit and transform at the same time.\"\"\"\n",
    "\n",
    "        self.fit(x)\n",
    "\n",
    "        transformed = self.transform(x)\n",
    "        return transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь стоит прояснить пару моментов..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratches",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
