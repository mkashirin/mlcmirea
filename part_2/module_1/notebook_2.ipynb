{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тетрадь 2: Преобразователи данных\n",
    "\n",
    "Предметом изучения в данной тетради являются преобразователи данных. Мы разберём, что они \n",
    "из себя представляют, как они устроены и для чего нужны.\n",
    "\n",
    "## Содержание\n",
    "\n",
    "- [Теория](#Теория)\n",
    "- [Примеры](#Примеры)\n",
    "\n",
    "Приступим теперь непосредственно к изучению материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория\n",
    "\n",
    "### Преобразование и предварительная обработка данных\n",
    "\n",
    "**Предварительная обработка данных** (Data Preprocessing) в машинном обучении — это набор методов и \n",
    "техник, которые применяются к исходным данным перед их использованием для обучения модели. Цель \n",
    "предварительной обработки — подготовить данные к анализу, улучшить их качество и сделать их более \n",
    "пригодными для обучения моделей машинного обучения.\n",
    "\n",
    "Вообще, существует множество различных этапов предварительной обработки данных. Однако в контексте \n",
    "данного курса мы будем относить всякие манипуляции, будь то очистка, сокращение размерности или \n",
    "форматирование, к преобразованиям данных. Отсюда **преобразователи данных** — программные интерфейсы \n",
    "(в основном классы), которые переводят данные из одного состояние в другое.\n",
    "\n",
    "Проиллюстрируем такой этап предобработки, как дополнение данных. Суть дополнения в том, что \n",
    "информация, которую вы где-либо раздобыли для анализа далеко не всегда является полной (например, в \n",
    "таблице присутствуют пустые поля). Ниже представлена диаграмма, которая схематично описывает эффект \n",
    "применения так называемого `Imputer`'а к данным с пропусками.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../images/imputer_scheme.png\" alt=\"Imputer Scheme\" width=512 height=256>\n",
    "</div>\n",
    "\n",
    "Как можно заметить на диаграмме, в первой таблице (Raw Data) присутствовали некоторые пропущенные \n",
    "поля. После пропуска данных через `Imputer` всё стало на свои места. Столбцы были заполнены по \n",
    "соответствующим закономерностям.\n",
    "\n",
    "### Некоторые этапы предварительной обработки данных\n",
    "\n",
    "Возвращась к разнообразию этапов предварительной обработки данных, пречислим некоторые из них: \n",
    "\n",
    "- **Разделение:** тренировочный/тестовый/валидационный набор; кросс-валидация.\n",
    "\n",
    "- **Очистка:** удаление дубликатов; обработка пропущенных значений; удаление шума.\n",
    "\n",
    "- **Масштабирование:** нормализация/Стандартизация (например, Min-Max нормализация, \n",
    "  Z-масштабирование); логарифмирование/экспоненцирование.\n",
    "\n",
    "- **Кодирование:** бинарное кодирование (One-Hot Encoding); лэйбл-кодирование (Label Encoding).\n",
    "\n",
    "- **Уменьшение Размерности:** PCA (Principal Component Analysis); t-SNE (t-distributed Stochastic \n",
    "  Neighbor Embedding); LDA (Linear Discriminant Analysis).\n",
    "\n",
    "### Порядок выполнения этапов предварительной обработки\n",
    "\n",
    "Очень важно помнить, что порядок выполнения этих этапов действительно имеет огромное значение.\n",
    "Сначала выполняется разделение данных, затем очистка, а потом уже всё остальное. Также далее мы \n",
    "обсудим не менее значимый нюанс касаемо применения преобразователей к отдельным наборам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры\n",
    "\n",
    "Рассмотрим теперь несколько упрощённых и один полный пример преобразователей данных. Начнём с \n",
    "более простых функций, а далее продемонстрируем полноценный класс. В качетве преобразования для \n",
    "примера возьмём Z-масштабирование. Формула для этой операции выглядит следующим образом:\n",
    "\n",
    "$$Z(X) = \\frac{X - \\textrm{mean}(X)}{\\textrm{std}(X)},$$\n",
    "\n",
    "где:\n",
    "- $X$ — множество всех точек данных признака;\n",
    "- $\\textrm{mean}(X)$ — среднее по $X$;\n",
    "- $\\textrm{std}(X)$ — стандартное отклонение по $X$.\n",
    "\n",
    "Запрограммируем функцию для Z-масштабирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "def z_scale(data: ndarray) -> ndarray:\n",
    "    scaled = (data - np.mean(data)) / np.std(data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь представим некоторый случайный набор данных и применим к нему нашу функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "[[ 1.037  0.572 -0.762 -0.308]\n",
      " [-0.921  0.667  1.11  -0.167]\n",
      " [ 0.452 -1.222 -1.058  0.672]\n",
      " [ 0.628  0.054  0.54   0.699]\n",
      " [-0.235  0.861  0.483 -1.549]\n",
      " [-0.471 -0.036  1.265 -0.131]\n",
      " [-0.616 -0.25   0.397 -0.246]\n",
      " [-0.622  0.985  0.962 -0.82 ]\n",
      " [ 0.383 -0.175 -0.276 -0.299]\n",
      " [-1.26  -1.553 -0.052  0.321]]\n",
      "\n",
      "After scaling:\n",
      "[[ 1.418  0.796 -0.987 -0.38 ]\n",
      " [-1.2    0.923  1.515 -0.192]\n",
      " [ 0.636 -1.602 -1.383  0.93 ]\n",
      " [ 0.871  0.104  0.753  0.966]\n",
      " [-0.283  1.182  0.677 -2.039]\n",
      " [-0.598 -0.017  1.722 -0.144]\n",
      " [-0.792 -0.303  0.562 -0.297]\n",
      " [-0.8    1.348  1.317 -1.065]\n",
      " [ 0.543 -0.202 -0.337 -0.368]\n",
      " [-1.653 -2.044 -0.038  0.461]]\n"
     ]
    }
   ],
   "source": [
    "(size, round_to) = ((10, 4), 3)\n",
    "selection = np.round(np.random.standard_normal(size), round_to)\n",
    "scaled = np.round(z_scale(selection), round_to)\n",
    "\n",
    "print(f\"Before scaling:\\n{selection}\\n\\nAfter scaling:\\n{scaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, всё работает отлично! Однако, есть нюанс, о котором было упомянуто в конце теоретического \n",
    "раздела, и сейчас мы его обусдим.\n",
    "\n",
    "Итак, представьте, что вы обучаете модель на тренировочных данных. Вы готовите её к взаимодействию \n",
    "с информацией, которую она ещё не видела. Но во время преобразования данных вы применяете инструмент \n",
    "трансформации к каждому из наборов (тренировочному и тестовому) по отдельности. То есть та же функция \n",
    "`z_scale()` принимает во внимание характеристики тестового набора данных при его масштабировании. \n",
    "Теперь представим, что тестового набора нет. Вам только предстоит его получить и обработать. \n",
    "Получается, для преобразования тестового набора данных нам нужно заглянуть в будущее!\n",
    "\n",
    "Многие начинающие часто совершают эту ошибку. Новички трансформируют тестовые данные, пользуясь их \n",
    "характеристиками. Хоть это и явное противоречие, часто его никто не замечает. Так что же делать с \n",
    "этим противоречием? \n",
    "\n",
    "Для решения этой проблемы нам понадобится хранить параметры тренировочных данных (минимум, максимум, \n",
    "среднее, медиану, стандартное отклонение и т.п.) и использовать их для преобразований тестовых. \n",
    "Рассмотрим конкретную реализацию.\n",
    "\n",
    "Для начала зададим интерфейс преобразователя в той форме, в которой нам будет удобно им пользоваться.\n",
    "За основу возьмём те же классы-трансформеры из библиотеки Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "class BasePreprocessor(ABC):\n",
    "    # The Base Preprocessor class is an abstract base class for preprocessor\n",
    "    # implementations.\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        self.copy = copy\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, x) -> None:\n",
    "        # Fit the preprocessor to the provided features.\n",
    "        message = \"Every preprocessor must implement the `fit()` method.\"\n",
    "        raise NotImplementedError(message)\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, x) -> Any:\n",
    "        # Transform the input features.\n",
    "        message = (\n",
    "            \"Every preprocessor must implement the `transform()` method.\"\n",
    "        )\n",
    "        raise NotImplementedError(message)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_values_masks(array: ndarray) -> Tuple[bool, bool]:\n",
    "        non_zero_values_mask = (array != 0)\n",
    "        zero_values_mask = ~non_zero_values_mask\n",
    "        return non_zero_values_mask, zero_values_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, это [абстрактный базовый класс](https://docs.python.org/3/library/abc.html). При \n",
    "инициализации мы задаём параметр `copy`, который нам пригодится в дальнейшем. Главное — у класса \n",
    "`BasePreprocessor` есть методы `fit()` и `transform()`. Первый отвечает за хранение характеристик \n",
    "данных, а второй за применение транформации с учётом самых характеристик. Есть также защищённый \n",
    "метод `_get_values_masks()`. О нём мы тоже поговорим чуть позже.\n",
    "\n",
    "Рассмотрим теперь конкретную реализаицю Z-масштабирующего преобразователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScalingPreprocessor(BasePreprocessor):\n",
    "    # Z-Scaling Preprocessor inherits from Base Preprocessor to provide method \n",
    "    # signatures and provide calls to `_get_values_masks()` through self-ref.\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        super().__init__(copy)\n",
    "        self.means: ndarray\n",
    "        self.stds: ndarray\n",
    "\n",
    "    def fit(self, x: ndarray) -> None:\n",
    "        # This method memotizes the data parameters of the input as attributes \n",
    "        # to use this information for Z-Scale calculation.\n",
    "        self.means = np.nanmean(x, axis=0)\n",
    "        self.stds = np.nanstd(x, axis=0)\n",
    "\n",
    "    def transform(self, x: ndarray) -> ndarray:\n",
    "        # This method applies the scaling formula excluding zero elements from \n",
    "        # the process.\n",
    "\n",
    "        # Use the copy if `copy` parameter was specifyed\n",
    "        if self.copy:\n",
    "            x = x.copy()\n",
    "\n",
    "        # Get zero and nonzero elements positions to avoid artefacts\n",
    "        (nonzero_std_mask, zero_std_mask) = self._get_values_masks(self.stds)\n",
    "        (nonzero_mean_mask, _) = self._get_values_masks(self.means)\n",
    "        x[:, zero_std_mask] = 0\n",
    "        \n",
    "        # Use the Z-Scale formula\n",
    "        x[:, nonzero_std_mask] = (\n",
    "            x[:, nonzero_std_mask] - self.means[nonzero_mean_mask]\n",
    "        ) / self.stds[nonzero_std_mask]\n",
    "        return x\n",
    "\n",
    "    def fit_transform(self, x) -> ndarray:\n",
    "        # Fit and transform at the same time.\"\"\"\n",
    "\n",
    "        self.fit(x)\n",
    "\n",
    "        transformed = self.transform(x)\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проясним некоорые моменты более подробно:\n",
    "\n",
    "- При вычислении среднего и стандартного отклочения в методе `fit()`, мы используем функции с \n",
    "  приставкой `nan*`. Это значит, что при подсчётах ячейки, содержащие `NaN` или любые другие \n",
    "  недействительные или нечисловые значения, будут проигнорированы.\n",
    "- Перед масштабированием с применением формулы мы отсекаем точки данных, что представляют собой \n",
    "  нули, для того чтобы избежать артефактов в виде отрицательных значений.\n",
    "\n",
    "Теперь посмотрим, насколько удачно можно применить вышеописанный интерфейс.\n",
    "\n",
    "Обязательно выполните следующую ячейку! В противном случае возникнет `ModuleNotFoundError` при \n",
    "попытке проверить правильность выполнения задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём непосредственно к демонстрации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train:\n",
      "[[-0.616 -0.25   0.397]\n",
      " [ 1.037  0.572 -0.762]\n",
      " [-0.921  0.667  1.11 ]\n",
      " [-1.26  -1.553 -0.052]\n",
      " [-0.622  0.985  0.962]\n",
      " [ 0.628  0.054  0.54 ]\n",
      " [ 0.383 -0.175 -0.276]\n",
      " [ 0.452 -1.222 -1.058]]\n",
      "\n",
      "X-test:\n",
      "[[-0.235  0.861  0.483]\n",
      " [-0.471 -0.036  1.265]]\n",
      "\n",
      "y-train:\n",
      "[[-0.246]\n",
      " [-0.308]\n",
      " [-0.167]\n",
      " [ 0.321]\n",
      " [-0.82 ]\n",
      " [ 0.699]\n",
      " [-0.299]\n",
      " [ 0.672]]\n",
      "\n",
      "y-test:\n",
      "[[-1.549]\n",
      " [-0.131]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from module_1 import DataSplitter\n",
    "\n",
    "splitter = DataSplitter(permute=True)\n",
    "scaler = ZScalingPreprocessor(copy=True)\n",
    "\n",
    "(x, y) = (selection[:,:-1], selection[:,-1].reshape((-1, 1)))\n",
    "(x_train, x_test, y_train, y_test) = splitter.split_data(x, y, test_size=0.25)\n",
    "\n",
    "nonscaled = (x_train, x_test, y_train, y_test)\n",
    "names = (\"X-train\", \"X-test\", \"y-train\", \"y-test\")\n",
    "for (nscld, name) in zip(nonscaled, names):\n",
    "    print(f\"{name}:\\n{nscld}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train scaled:\n",
      "[[-0.639 -0.161  0.395]\n",
      " [ 1.469  0.819 -1.187]\n",
      " [-1.028  0.932  1.368]\n",
      " [-1.461 -1.713 -0.218]\n",
      " [-0.647  1.311  1.166]\n",
      " [ 0.948  0.202  0.59 ]\n",
      " [ 0.635 -0.071 -0.524]\n",
      " [ 0.723 -1.318 -1.591]]\n",
      "\n",
      "X-test scaled:\n",
      "[[-0.153  1.163  0.512]\n",
      " [-0.454  0.094  1.58 ]]\n",
      "\n",
      "y-train scaled:\n",
      "[[-0.457]\n",
      " [-0.581]\n",
      " [-0.298]\n",
      " [ 0.681]\n",
      " [-1.609]\n",
      " [ 1.44 ]\n",
      " [-0.563]\n",
      " [ 1.386]]\n",
      "\n",
      "y-test scaled:\n",
      "[[-3.072]\n",
      " [-0.226]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled = (\n",
    "    scaler.fit_transform(x_train), \n",
    "    scaler.transform(x_test),\n",
    "    scaler.fit_transform(y_train), \n",
    "    scaler.transform(y_test),\n",
    ")\n",
    "\n",
    "names = (\"X-train scaled\", \"X-test scaled\", \"y-train scaled\", \"y-test scaled\")\n",
    "for (scld, name) in zip(scaled, names):\n",
    "    print(f\"{name}:\\n{np.round(scld, 3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "### Задание 1\n",
    "\n",
    "По аналогии с заданием в примерах реализуйте класс для MinMax масштабирования, наследуя от базового \n",
    "класса `BasePreprocessor`. В качестве подсказки рассмотрите следующую формулу:\n",
    "\n",
    "$$ \\textrm{MinMax(X)} = \\frac{X - \\textrm{min}(X)}{\\textrm{max}(X) - \\textrm{min}(X)}, $$\n",
    "\n",
    "где:\n",
    "- $X$ — множество всех точек данных признака;\n",
    "- $\\textrm{min}(X)$ — минимум по $X$;\n",
    "- $\\textrm{max}(X)$ — максимум по $X$.\n",
    "\n",
    "В процессе решения не забудьте про маски для нулевых значений!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMScalingPreprocessor(BasePreprocessor):\n",
    "    # MinMax Scaling Preprocessor inherits from Base Preprocessor to provide  \n",
    "    # method signatures and provide calls to `_get_values_masks()` through \n",
    "    # self-ref.\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        super.__init__(copy)\n",
    "        self.min_values: ndarray\n",
    "        self.max_values: ndarray\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда реализуете класс из ячейки выше, запускайте ячейку ниже и продемонстрируйте правильность \n",
    "выполнения задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class MMScalingPreprocessor without an implementation for abstract methods 'fit', 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m splitter \u001b[38;5;241m=\u001b[39m DataSplitter(permute\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mMMScalingPreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m (x, y) \u001b[38;5;241m=\u001b[39m (selection[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], selection[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m      5\u001b[0m (x_train, x_test, y_train, y_test) \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit_data(\n\u001b[0;32m      6\u001b[0m     x, \n\u001b[0;32m      7\u001b[0m     y, \n\u001b[0;32m      8\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,\n\u001b[0;32m      9\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2024\u001b[39m,\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class MMScalingPreprocessor without an implementation for abstract methods 'fit', 'transform'"
     ]
    }
   ],
   "source": [
    "splitter = DataSplitter(permute=True)\n",
    "scaler = MMScalingPreprocessor(copy=True)\n",
    "\n",
    "(x, y) = (selection[:,:-1], selection[:,-1].reshape((-1, 1)))\n",
    "(x_train, x_test, y_train, y_test) = splitter.split_data(\n",
    "    x, \n",
    "    y, \n",
    "    test_size=0.25,\n",
    "    random_seed=2024,\n",
    ")\n",
    "\n",
    "nonscaled = (x_train, x_test, y_train, y_test)\n",
    "names = (\"X-train\", \"X-test\", \"y-train\", \"y-test\")\n",
    "for (nscld, name) in zip(nonscaled, names):\n",
    "    print(f\"{name}:\\n{nscld}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2*\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratches",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
