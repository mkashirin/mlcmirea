{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тетрадь 1: Разделение данных\n",
    "\n",
    "В настоящей тетради будут разобраны основные принципы разделения данных. Мы разберёмся, как и зачем \n",
    "делят данные на этапе предварительной обработки данных.\n",
    "\n",
    "## Содержание\n",
    "\n",
    "Можете пользоваться следующими гиперссылками для навигации:\n",
    "- [Теория](#Теория)\n",
    "- [Примеры](#Примеры)\n",
    "- [Задание](#Задание)\n",
    "\n",
    "Приступим теперь непосредственно к материалу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Теория\n",
    "\n",
    "### Предварительная обработка данных\n",
    "\n",
    "**Предварительная обработка данных (Data Preprocessing)** в машинном обучении — это набор методов и \n",
    "техник, которые применяются к исходным данным перед их использованием для обучения модели. Цель \n",
    "предварительной обработки — подготовить данные к анализу, улучшить их качество и сделать их более \n",
    "пригодными для обучения моделей машинного обучения. Существует множество различных этапов \n",
    "предобработки, о которых более подробно речь пойдёт в следующей тетради. А пока остновимся на том, \n",
    "что одним из самых этапов является разделение данных на обучающую, тестовую и валидационную выборки.\n",
    "\n",
    "### Разделение на обучающую и тестовую выборки\n",
    "\n",
    "Схематически разделение на обучающую и тестовую выборки можно изобразить следующим образом:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../images/train_test.png\" alt=\"Train Test Split\" width=512 height=256>\n",
    "</div>\n",
    "\n",
    "Рассмотрим данную операцию более подробно.\n",
    "\n",
    "**Цель.** Оценка обобщающей способности модели.\n",
    "\n",
    "**Принцип.** Данные делятся на две части:\n",
    "- Обучающая выборка (обычно 70-80%) — Используется для обучения модели.\n",
    "- Тестовая выборка (обычно 20-30%) — Используется для оценки качества модели на новых данных, \n",
    "которые модель не видела во время обучения.\n",
    "\n",
    "**Важность.** Если модель обучается и тестируется на одних и тех же данных, она может запомнить их, \n",
    "а не научиться обобщать. Тестовая выборка позволяет оценить, насколько хорошо модель будет работать \n",
    "на новых, неизвестных данных.\n",
    "\n",
    "### Разделение на обучающую, валидационную и тестовую выборки\n",
    "\n",
    "Так же схематично представим разделение на обучающую, валидационную и етстовую выборки:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../images/train_test_valid.png\" alt=\"Train Test Valid Split\" width=512 height=256>\n",
    "</div>\n",
    "\n",
    "Обсудим, чем этот метод отличается от предыдущего, более подробно.\n",
    "\n",
    "**Цель.** Настройка гиперпараметров модели. Выбор лучшей модели.\n",
    "\n",
    "**Принцип.** Данные делятся на три части:\n",
    "- Обучающая выборка (обычно 60-70%) — Используется для обучения модели.\n",
    "- Валидационная выборка (обычно 10-20%) — Используется для настройки гиперпараметров и выбора лучшей \n",
    "модели.\n",
    "- Тестовая выборка (обычно 10-20%) — Используется для окончательной оценки качества выбранной \n",
    "модели.\n",
    "\n",
    "**Важность.** Валидационная выборка позволяет: оценивать качество модели на данных, которые модель \n",
    "не видела во время обучения, но при этом не смешивается с тестовой выборкой; выбирать \n",
    "гиперпараметры, которые дают лучшие результаты на данных, не используемых для обучения; сравнивать \n",
    "разные модели и выбирать ту, которая показывает лучшие результаты на данных, не используемых для \n",
    "обучения.\n",
    "\n",
    "Разделение данных на обучающую, тестовую и валидационную выборки является важным этапом \n",
    "предварительной обрабоки данных в машинном обучении и искусственном интеллекте. Оно позволяет\n",
    "оценить обобщающую способность модели, предотвратить переобучение и настроить гиперпараметры.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры\n",
    "\n",
    "Рассмотрим теперь некоторые элементарные примеры разделения данных. \n",
    "\n",
    "Допустим, имеется следующая случайная выборка из 10 чисел:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.08  -2.461  0.781  1.261  0.755 -0.206  0.516  0.853 -0.013 -0.464]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "(n_samples, round_to) = (10, 3)\n",
    "selection = np.round(np.random.standard_normal(n_samples), round_to)\n",
    "\n",
    "print(selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на обучающую и тестовую выборки\n",
    "\n",
    "Рассмотрим случай, когда нужно выделить только обучающую и тестовую выборки. Наша задача в том, \n",
    "чтобы разделить эти данные в соотношении 70 (обучающая выборка) на 30 (тестовая выборка). Напишем \n",
    "для этого функцию и посмотрим, как будет выглядеть результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1.261,  0.755, -0.206,  0.516,  0.853, -0.013, -0.464]), array([ 2.08 , -2.461,  0.781]))\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "def split_data(data: ndarray, test_size: float) -> Tuple[ndarray, ndarray]:\n",
    "    # Calculating the splitting index\n",
    "    train_test_index = int(test_size * len(data))\n",
    "    # Cutting off the training set\n",
    "    train_data = data[train_test_index:] \n",
    "    # Cutting off the testing set\n",
    "    test_data = data[:train_test_index]\n",
    "\n",
    "    splitted: Tuple[ndarray, ndarray] = (train_data, test_data)\n",
    "    return splitted\n",
    "\n",
    "\n",
    "data_splitted = split_data(selection, 0.3)\n",
    "\n",
    "print(data_splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на обучающую, валидационную и тестовую выборки\n",
    "\n",
    "Теперь посмотрим, как действовать, если помимо обучающей и тестовой имеется потребность выделить \n",
    "ещё и валидационную выборку. Дополним функцию из предыдущей секции. Теперь помимо параметра \n",
    "`test_size`, у нас будет `valid_size`, который обозначает часть тестовой выборки, что будет \n",
    "отсечена в валидационную. Оставим 70% для тренировочной выборки, а треть тестовой определим в \n",
    "валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1.261,  0.755, -0.206,  0.516,  0.853, -0.013, -0.464]), array([-2.461,  0.781]), array([-2.461]))\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def split_data_with_valid(\n",
    "    data: ndarray, test_size: float, valid_size: Optional[float] = None\n",
    ") -> Tuple[ndarray, ndarray, ndarray]:\n",
    "    splitted: Tuple[ndarray, ndarray] = split_data(data, test_size)\n",
    "\n",
    "    if valid_size is not None:\n",
    "        (train_data, test_data) = (splitted[0], splitted[1])\n",
    "        # Calculating the splitting index for the testing set\n",
    "        test_valid_index = int(valid_size * len(test_data))\n",
    "        # Split the testing set the same way as in `split_data()` funciton \n",
    "        test_data = test_data[test_valid_index:]\n",
    "        valid_data = test_data[:test_valid_index]\n",
    "        splitted: Tuple[ndarray, ndarray, ndarray] = (\n",
    "            train_data, test_data, valid_data\n",
    "        )\n",
    "\n",
    "    return splitted\n",
    "\n",
    "\n",
    "data_splitted = split_data_with_valid(selection, 0.3, 0.4)\n",
    "\n",
    "print(data_splitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда у нас уже имеется некоторое базовое представление о разделении данных на обучающую, \n",
    "тестовую и валидационную выборки, можно выполнить небольшое задания для закрепления материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "В данном задании Вам нужно, пользуясь примерами выше, дополнить тела защищённых \n",
    "(тех, что начинаются с нижнего подчёркивания) функций классв `DataSplitter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "Selections = Union[\n",
    "    Tuple[ndarray, ndarray, ndarray, ndarray],\n",
    "    Tuple[ndarray, ndarray, ndarray, ndarray, ndarray, ndarray],\n",
    "]\n",
    "\n",
    "\n",
    "class DataSplitter:\n",
    "\n",
    "    def __init__(\n",
    "        self, permute: bool = False, random_seed: Optional[int] = None\n",
    "    ):\n",
    "        self.random_seed = random_seed\n",
    "        self.permute = permute\n",
    "        self._selections: List[ndarray]\n",
    "\n",
    "    def split_data(\n",
    "        self,\n",
    "        x: ndarray,\n",
    "        y: ndarray,\n",
    "        *,\n",
    "        test_size: float,\n",
    "        valid_size: Optional[float] = None,\n",
    "    ) -> Selections:\n",
    "        if self.random_seed:\n",
    "            np.random.seed(self.random_seed)\n",
    "        if self.permute:\n",
    "            permutation = np.random.permutation(x.shape[0])\n",
    "            x, y = x[permutation], y[permutation]\n",
    "\n",
    "        self._set_standard(x, y, test_size)\n",
    "        if valid_size:\n",
    "            test_length = self._selections[1].shape[0]\n",
    "            self._add_valid(test_length, x, y, valid_size)\n",
    "\n",
    "        selections: Selections = tuple(\n",
    "            self._selections  # pyright: ignore[reportAssignmentType]\n",
    "        )\n",
    "        return selections\n",
    "\n",
    "    def _set_standard(self, x: ndarray, y: ndarray, test_size: float) -> None:\n",
    "        \"\"\"This method splits two multidimensional sets of data with equal  \n",
    "        lengths (`x` и `y`) into training and testing selections.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"Method `_set_standard()` must be implemented!\"\n",
    "        )\n",
    "\n",
    "    def _add_valid(\n",
    "        self, test_length: int, x: ndarray, y: ndarray, valid_size: float\n",
    "    ) -> None:\n",
    "        \"\"\"This method splits two multidimensional sets of data with equal  \n",
    "        lengths (`x` и `y`) into testing and validation selections.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"Method `_add_valid()` must be implemented!\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все assertion'ы в следующей секции должны выполниться без ошибок!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка\n",
    "\n",
    "Обязательно выполните следующую ячейку! В противном случае возникнет `ModuleNotFoundError` при \n",
    "попытке проверить правильность выполнения задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите ячейку ниже, чтобы понять, правильно ли Вы выполнили задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Метод `_set_standard()` должен быть обязательно реализован!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcheckers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_notebook_1_task_1\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcheck_notebook_1_task_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataSplitter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Desktop Access\\Documents\\mlcmirea\\part_2\\module_1\\..\\checkers\\module_1.py:17\u001b[0m, in \u001b[0;36mcheck_notebook_1_task_1\u001b[1;34m(splitter)\u001b[0m\n\u001b[0;32m     14\u001b[0m expected_train_len \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m expected_test_len\n\u001b[0;32m     15\u001b[0m expected_valid_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(expected_test_len \u001b[38;5;241m*\u001b[39m valid_size)\n\u001b[1;32m---> 17\u001b[0m splitted \u001b[38;5;241m=\u001b[39m \u001b[43mdata_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m ((x_train, x_test), (y_train, y_test)) \u001b[38;5;241m=\u001b[39m splitted\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(x_train \u001b[38;5;241m!=\u001b[39m x[expected_test_len:])\n",
      "Cell \u001b[1;32mIn[11], line 32\u001b[0m, in \u001b[0;36mDataSplitter.split_data\u001b[1;34m(self, x, y, test_size, valid_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m     permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     30\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x[permutation], y[permutation]\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_size:\n\u001b[0;32m     34\u001b[0m     test_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selections[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m, in \u001b[0;36mDataSplitter._set_standard\u001b[1;34m(self, x, y, test_size)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: ndarray, y: ndarray, test_size: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Этот метод разделяет два многомерных набора данных одинаковой длины \u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    (`x` и `y`) на обучающую и тестовую выборки.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mМетод `_set_standard()` должен быть обязательно реализован!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Метод `_set_standard()` должен быть обязательно реализован!"
     ]
    }
   ],
   "source": [
    "from checkers.module_1 import check_notebook_1_task_1\n",
    "\n",
    "check_notebook_1_task_1(DataSplitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если никаих ошибок не возникло, можете поэкспериментировать с кодом в задании или реализовать \n",
    "собственный интерфейс, а затем проверить его при помощи функции выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "В настоящей тетради мы изучили: что такое разделение данных на обучающую, тестовую и валидационную \n",
    "выборки; как, а самое главное — для чего выполняется такое разделение. \n",
    "\n",
    "Если есть интерес, можете попробовать далее модифицровать код из секций выше. Также можете \n",
    "попробовать написать собственный интерфейс, который вам покажется более удобным."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
