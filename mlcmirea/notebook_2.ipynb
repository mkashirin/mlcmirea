{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тетрадь 2: Преобразователи данных\n",
    "\n",
    "Предметом изучения в данной тетради являются преобразователи данных. Мы разберём, что они \n",
    "из себя представляют, как они устроены и для чего нужны.\n",
    "\n",
    "## Содержание\n",
    "\n",
    "- [Теория](#Теория)\n",
    "- [Примеры](#Примеры)\n",
    "- [Задания](#Задания)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория\n",
    "\n",
    "### Преобразование и предварительная обработка данных\n",
    "\n",
    "**Предварительная обработка данных** (Data Preprocessing) в машинном обучении — это набор методов\n",
    "и техник, которые применяются к исходным данным перед их использованием для обучения модели. Цель \n",
    "предварительной обработки — подготовить данные к анализу, улучшить их качество и сделать их более \n",
    "пригодными для обучения моделей машинного обучения.\n",
    "\n",
    "Вообще, существует множество различных этапов предварительной обработки данных. Однако в контексте \n",
    "данного курса мы будем относить всякие манипуляции, будь то очистка, сокращение размерности или \n",
    "форматирование, к преобразованиям данных. Отсюда **преобразователи данных** — программные интерфейсы \n",
    "(в основном классы), которые переводят данные из одного состояние в другое.\n",
    "\n",
    "Проиллюстрируем такой этап предобработки, как дополнение данных. Суть дополнения в том, что \n",
    "информация, которую вы где-либо раздобыли для анализа далеко не всегда является полной (например, в\n",
    "таблице присутствуют пустые поля). Ниже представлена диаграмма, которая схематично описывает эффект\n",
    "применения так называемого `Preprocessor`'а к «сырым» данным.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"images/imputer_scheme_plot.png\" alt=\"Imputer Scheme\">\n",
    "</div>\n",
    "\n",
    "### Некоторые этапы предварительной обработки данных\n",
    "\n",
    "Возвращась к разнообразию этапов предварительной обработки данных, пречислим некоторые из них: \n",
    "\n",
    "- **Разделение:** тренировочный/тестовый/валидационный набор; кросс-валидация.\n",
    "\n",
    "- **Очистка:** удаление дубликатов; обработка пропущенных значений; удаление шума.\n",
    "\n",
    "- **Масштабирование:** нормализация/Стандартизация (например, Min-Max нормализация, \n",
    "  Z-масштабирование); логарифмирование/экспоненцирование.\n",
    "\n",
    "- **Кодирование:** бинарное кодирование (One-Hot Encoding); лэйбл-кодирование (Label Encoding).\n",
    "\n",
    "- **Уменьшение Размерности:** PCA (Principal Component Analysis); t-SNE (t-distributed Stochastic \n",
    "  Neighbor Embedding); LDA (Linear Discriminant Analysis).\n",
    "\n",
    "### Порядок выполнения этапов предварительной обработки\n",
    "\n",
    "Очень важно помнить, что порядок выполнения этих этапов действительно имеет огромное значение.\n",
    "Сначала выполняется разделение данных, затем очистка, а потом уже всё остальное. Также далее мы \n",
    "обсудим не менее значимый нюанс касаемо применения преобразователей к отдельным наборам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры\n",
    "\n",
    "Рассмотрим теперь несколько упрощённых и один полный пример преобразователей данных. Начнём с \n",
    "более простых функций, а далее продемонстрируем полноценный класс. В качетве преобразования для \n",
    "примера возьмём Z-масштабирование. Формула для этой операции выглядит следующим образом:\n",
    "\n",
    "$$Z(X) = \\frac{X - \\textrm{mean}(X)}{\\textrm{std}(X)},$$\n",
    "\n",
    "где:\n",
    "- $X$ — множество всех точек данных признака;\n",
    "- $\\textrm{mean}(X)$ — среднее по $X$;\n",
    "- $\\textrm{std}(X)$ — стандартное отклонение по $X$.\n",
    "\n",
    "Запрограммируем функцию для Z-масштабирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "def z_scale(data: ndarray) -> ndarray:\n",
    "    scaled = (data - np.mean(data)) / np.std(data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь представим некоторый случайный набор данных и применим к нему нашу функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(size, round_to) = ((10, 4), 3)\n",
    "selection = np.round(np.random.standard_normal(size), round_to)\n",
    "scaled = np.round(z_scale(selection), round_to)\n",
    "\n",
    "print(f\"Before scaling:\\n{selection}\\n\\nAfter scaling:\\n{scaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, всё работает отлично! Однако, есть нюанс, о котором было упомянуто в конце\n",
    "теоретического раздела, и сейчас мы его обусдим.\n",
    "\n",
    "Итак, представьте, что вы обучаете модель на тренировочных данных. Вы готовите её к взаимодействию \n",
    "с информацией, которую она ещё не видела. Но во время преобразования данных вы применяете\n",
    "инструмент трансформации к каждому из наборов (тренировочному и тестовому) по отдельности.\n",
    "\n",
    "То есть та же функция `z_scale()` принимает во внимание характеристики тестового набора данных при\n",
    "его масштабировании. Теперь представим, что тестового набора нет. Вам только предстоит его получить\n",
    "и обработать. Получается, для преобразования тестового набора данных нам нужно заглянуть в будущее!\n",
    "\n",
    "Многие начинающие часто совершают эту ошибку. Новички трансформируют тестовые данные, пользуясь их \n",
    "характеристиками. Хоть это и явное противоречие, часто его никто не замечает. Так что же делать с \n",
    "этим противоречием?\n",
    "\n",
    "Для решения этой проблемы нам понадобится хранить параметры тренировочных данных (минимум,\n",
    "максимум, среднее, медиану, стандартное отклонение и т.п.) и использовать их для преобразований\n",
    "тестовых. Рассмотрим конкретную реализацию.\n",
    "\n",
    "### Базовый класс преобразователей\n",
    "\n",
    "Для начала определим интерфейс преобразователя в удобной в пользовании форме. За основу возьмём те\n",
    "же классы-трансформеры из библиотеки Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "class BasePreprocessor(ABC):\n",
    "    # The Base Preprocessor class is an abstract base class for preprocessor\n",
    "    # implementations.\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        self.copy = copy\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, x: ndarray) -> None:\n",
    "        # Fit the preprocessor to the provided features.\n",
    "        message = \"Every preprocessor must implement the `fit()` method.\"\n",
    "        raise NotImplementedError(message)\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, x: ndarray) -> Any:\n",
    "        # Transform the input features.\n",
    "        message = \"Every preprocessor must implement the `transform()` method.\"\n",
    "        raise NotImplementedError(message)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_values_masks(array: ndarray) -> Tuple[bool, bool]:\n",
    "        non_zero_values_mask = array != 0\n",
    "        zero_values_mask = ~non_zero_values_mask\n",
    "        return non_zero_values_mask, zero_values_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, это [абстрактный базовый класс](https://docs.python.org/3/library/abc.html). При \n",
    "инициализации мы задаём параметр `copy`, который нам пригодится в дальнейшем. Главное — у класса \n",
    "`BasePreprocessor` есть методы `fit()` и `transform()`. Первый отвечает за хранение характеристик \n",
    "данных, а второй за применение транформации с учётом самых характеристик. Есть также защищённый \n",
    "метод `_get_values_masks()`. О нём мы тоже поговорим чуть позже.\n",
    "\n",
    "### Z-масштабировщик\n",
    "\n",
    "Рассмотрим теперь конкретную реализаицю Z-масштабирующего преобразователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScalingPreprocessor(BasePreprocessor):\n",
    "    # Z-Scaling Preprocessor inherits from Base Preprocessor to provide method\n",
    "    # signatures and calls to `_get_values_masks()` through self-ref.\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        super().__init__(copy)\n",
    "        self.means: ndarray\n",
    "        self.stds: ndarray\n",
    "\n",
    "    def fit(self, x: ndarray) -> None:\n",
    "        # This method memorizes the data parameters of the input as attributes\n",
    "        # to use this information for Z-Scale calculation.\n",
    "        self.means = np.nanmean(x, axis=0)\n",
    "        self.stds = np.nanstd(x, axis=0)\n",
    "\n",
    "    def transform(self, x: ndarray) -> ndarray:\n",
    "        # This method applies the scaling formula excluding zero elements from\n",
    "        # the process.\n",
    "\n",
    "        # Use the copy if `copy` parameter was specifyed\n",
    "        if self.copy:\n",
    "            x = x.copy()\n",
    "\n",
    "        # Get zero and nonzero elements positions to avoid artefacts\n",
    "        (nonzero_std_mask, zero_std_mask) = self._get_values_masks(self.stds)\n",
    "        (nonzero_mean_mask, _) = self._get_values_masks(self.means)\n",
    "        x[:, zero_std_mask] = 0\n",
    "\n",
    "        # Use the Z-Scale formula\n",
    "        x[:, nonzero_std_mask] = (\n",
    "            x[:, nonzero_std_mask] - self.means[nonzero_mean_mask]\n",
    "        ) / self.stds[nonzero_std_mask]\n",
    "        return x\n",
    "\n",
    "    def fit_transform(self, x) -> ndarray:\n",
    "        # Fit and transform at the same time.\"\"\"\n",
    "\n",
    "        self.fit(x)\n",
    "\n",
    "        transformed = self.transform(x)\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проясним некоорые моменты более подробно:\n",
    "\n",
    "- При вычислении среднего и стандартного отклочения в методе `fit()`, мы используем функции с \n",
    "  приставкой `nan*`. Это значит, что при подсчётах ячейки, содержащие `NaN` или любые другие \n",
    "  недействительные или нечисловые значения, будут проигнорированы.\n",
    "- Перед масштабированием с применением формулы мы отсекаем точки данных, что представляют собой \n",
    "  нули, для того чтобы избежать артефактов в виде отрицательных значений.\n",
    "\n",
    "Теперь посмотрим, насколько удачно можно применить вышеописанный интерфейс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.preprocessing import DataSplitter\n",
    "\n",
    "\n",
    "splitter = DataSplitter(permute=True)\n",
    "scaler = ZScalingPreprocessor(copy=True)\n",
    "\n",
    "(x, y) = (selection[:, :-1], selection[:, -1].reshape((-1, 1)))\n",
    "(x_train, x_test, y_train, y_test) = splitter.split_data(x, y, test_size=0.25)\n",
    "\n",
    "nonscaled = (x_train, x_test, y_train, y_test)\n",
    "names = (\"X-train\", \"X-test\", \"y-train\", \"y-test\")\n",
    "for nscld, name in zip(nonscaled, names):\n",
    "    print(f\"{name}:\\n{nscld}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = (\n",
    "    scaler.fit_transform(x_train),\n",
    "    scaler.transform(x_test),\n",
    "    scaler.fit_transform(y_train),\n",
    "    scaler.transform(y_test),\n",
    ")\n",
    "\n",
    "names = (\"X-train scaled\", \"X-test scaled\", \"y-train scaled\", \"y-test scaled\")\n",
    "for scld, name in zip(scaled, names):\n",
    "    print(f\"{name}:\\n{np.round(scld, 3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания\n",
    "\n",
    "### Задание 1\n",
    "\n",
    "По аналогии с заданием в примерах реализуйте класс для MinMax масштабирования, наследуя от базового \n",
    "класса `BasePreprocessor`. В качестве подсказки рассмотрите следующую формулу:\n",
    "\n",
    "$$ \\textrm{MinMax(X)} = \\frac{X - \\textrm{min}(X)}{\\textrm{max}(X) - \\textrm{min}(X)}, $$\n",
    "\n",
    "где:\n",
    "- $X$ — множество всех точек данных признака;\n",
    "- $\\textrm{min}(X)$ — минимум по $X$;\n",
    "- $\\textrm{max}(X)$ — максимум по $X$.\n",
    "\n",
    "В процессе решения не забудьте про маски для нулевых значений!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMScalingPreprocessor(BasePreprocessor):\n",
    "    # MinMax Scaling Preprocessor inherits from Base Preprocessor to provide\n",
    "    # method signatures and provide calls to `_get_values_masks()` through\n",
    "    # self-ref.\n",
    "\n",
    "    def __init__(self, copy: bool = True) -> None:\n",
    "        super.__init__(copy)\n",
    "        self.min_values: ndarray\n",
    "        self.max_values: ndarray\n",
    "\n",
    "    def fit(self, x: ndarray) -> None:\n",
    "        # This method should fit the transformer to the data.\n",
    "        ...\n",
    "\n",
    "    def transform(self, x: ndarray) -> Any:\n",
    "        # This method should transform the data accordingly to the state,\n",
    "        # produced by the :meth:`fit()` method.\n",
    "        ...\n",
    "\n",
    "    def fit_transform(self, x: ndarray) -> Any:\n",
    "        # This method just combines both :meth:`fit()` and :meth:`transform()`.\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда реализуете класс из ячейки выше, запускайте ячейку ниже и продемонстрируйте правильность \n",
    "выполнения задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DataSplitter(permute=True)\n",
    "scaler = MMScalingPreprocessor(copy=True)\n",
    "\n",
    "(x, y) = (selection[:, :-1], selection[:, -1].reshape((-1, 1)))\n",
    "(x_train, x_test, y_train, y_test) = splitter.split_data(\n",
    "    x, y, test_size=0.25, random_seed=2024\n",
    ")\n",
    "\n",
    "nonscaled = (x_train, x_test, y_train, y_test)\n",
    "names = (\"X-train\", \"X-test\", \"y-train\", \"y-test\")\n",
    "for nscld, name in zip(nonscaled, names):\n",
    "    print(f\"{name}:\\n{nscld}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2*\n",
    "\n",
    "Данное задание обладает повышенной сложностью выполнения. Тут вам предстоит самостоятельно и без\n",
    "каких-либо подсказок реализовать класс `ImputingPreprocessor`, который будет иметь функционал,\n",
    "описанный в [теории](#теория). Данный интерфейс должен быть способен выполнить замену недостающих\n",
    "значений (например, `NaN`) по трём стратегиям: константа, среднее и медиана по столбцу. **Важно\n",
    "помнить, что все дополнения воспроизводятся относительно столбцов!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputingPreprocessor(BasePreprocessor):\n",
    "    # This class should implement an interface for imputing the missing values\n",
    "    # by one of these strategies: \"constant\", \"mean\" and \"median\".\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, как и в случае с предыдущим заданием, выполните ячейку ниже, когда закончите выполнять\n",
    "задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random as nprand\n",
    "\n",
    "\n",
    "na_shape = (5, 5)\n",
    "nan_array = np.random.standard_normal(na_shape)\n",
    "for i in range(na_shape[0]):\n",
    "    for j in range(na_shape[1]):\n",
    "        nan_array[i, j] = np.nan if nprand() > 0.8 else nan_array[i, j]\n",
    "\n",
    "imputer = ImputingPreprocessor(...)\n",
    "na_imputed = imputer.fit_transform(nan_array)\n",
    "\n",
    "print(f\"Before imputing:\\n{nan_array}\\n\")\n",
    "print(f\"After imputing:\\n{na_imputed}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "В настоящей тетради мы: поближе познакомились с предварительной обработкой данных и некоторыми\n",
    "её этапами; изучили, что такое преобразователи данных, для чего они нужны, как ими пользоваться,\n",
    "а самое главное — научились самостоятельно их воспроизводить!\n",
    "\n",
    "Если есть интерес, можете попробовать далее модифицровать код из секций выше. Также можете \n",
    "попробовать написать собственный интерфейс, который вам покажется более удобным."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratches",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
