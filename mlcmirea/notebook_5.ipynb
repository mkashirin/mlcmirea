{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тетрадь 5: Элементарная классификация\n",
    "\n",
    "## Содержание\n",
    "\n",
    "- [Введение](#Ввдение)\n",
    "- [Код и примеры](#Код-и-примеры)\n",
    "- [Задания](#Задания)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "\n",
    "Классификация — это одна из ключевых задач в машинном обучении, которая заключается в отнесении\n",
    "объектов к одному из заранее определённых классов на основе их признаков. Классификация широко\n",
    "применяется в различных областях, таких как распознавание изображений, фильтрация спама,\n",
    "медицинская диагностика, кредитный скоринг и многих других.\n",
    "\n",
    "### Основные принципы работы моделей классификации\n",
    "\n",
    "1. **Признаки (Features)** — это характеристики объектов, которые используются для классификации.\n",
    "Например, для классификации писем на спам и не спам признаками могут быть частота употребления\n",
    "определённых слов, длина письма и т.д.\n",
    "2. **Классы (Labels)** — это категории, к которым относятся объекты. В задаче классификации писем\n",
    "это может быть «спам» или «не спам».\n",
    "3. **Обучение модели** — процесс, при котором модель на основе обучающих данных (набор объектов с\n",
    "известными классами) находит закономерности, позволяющие предсказывать класс новых объектов.\n",
    "4. **Предсказание** — применение обученной модели к новым данным для определения их класса.\n",
    "\n",
    "### Типы моделей классификации\n",
    "\n",
    "#### Логистическая регрессия (Logistic Regression)\n",
    "\n",
    "- Используется для бинарной классификации.\n",
    "- Модель оценивает вероятность принадлежности объекта к одному из классов на основе линейной\n",
    "комбинации признаков.\n",
    "\n",
    "**Пример:** предсказание, будет ли клиент возвращать кредит.\n",
    "\n",
    "#### Деревья решений (Decision Trees)\n",
    "\n",
    "- Модель строит дерево, где каждый узел представляет собой условие на основе признаков, а листья —\n",
    "классы.\n",
    "- Проста в интерпретации, но склонна к переобучению.\n",
    "\n",
    "**Пример:** классификация клиентов по уровню дохода.\n",
    "\n",
    "#### Случайный лес (Random Forest)\n",
    "\n",
    "- Ансамбль деревьев решений, где каждое дерево обучается на случайной подвыборке данных.\n",
    "- Уменьшает риск переобучения и повышает точность.\n",
    "\n",
    "**Пример:** предсказание оттока клиентов.\n",
    "\n",
    "#### Метод k-ближайших соседей (KNN)\n",
    "\n",
    "Непараметрический метод, который классифицирует объект на основе классов его ближайших соседей в\n",
    "пространстве признаков.\n",
    "\n",
    "**Пример:** распознавание рукописного текста.\n",
    "\n",
    "#### Нейронные сети\n",
    "\n",
    "- Используются для сложных задач, таких как классификация изображений или текстов.\n",
    "- Состоят из множества слоёв, которые автоматически извлекают признаки из данных.\n",
    "\n",
    "**Пример:** распознавание лиц.\n",
    "\n",
    "#### Наивный байесовский классификатор\n",
    "- Основан на теореме Байеса и предположении о независимости признаков.\n",
    "- Эффективен для текстовой классификации.\n",
    "\n",
    "**Пример:** фильтрация спама."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код и примеры\n",
    "\n",
    "Перед тем как погрузиться в практическую часть, выполним все необходимые импорты и опрделим\n",
    "вспомогательные функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from logging import basicConfig, INFO\n",
    "from typing import Any, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from modules.metrics import ConfusionMatrix, compute_confusion_matrix\n",
    "from modules.preprocessing import DataSplitter\n",
    "\n",
    "\n",
    "def random_list(length: int) -> List:\n",
    "    return [np.random.random() for _ in range(length)]\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    confusion_matrix: ConfusionMatrix, title: str\n",
    ") -> None:\n",
    "    matrix, _ = confusion_matrix\n",
    "    figure, axis = plt.subplots()\n",
    "    ticks = list(range(0, len(matrix)))\n",
    "\n",
    "    axis.set_yticks(ticks)\n",
    "    axis.set_xticks(ticks)\n",
    "    axis.set_xlabel(\"Actual\")\n",
    "    axis.set_ylabel(\"Predicted\")\n",
    "    for i, _ in enumerate(matrix):\n",
    "        for j, _ in enumerate(matrix):\n",
    "            # fmt: off\n",
    "            axis.text(\n",
    "                j, i,\n",
    "                int(matrix[i, j]),\n",
    "                verticalalignment=\"center\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\",\n",
    "            )\n",
    "            # fmt: on\n",
    "    axis.set_title(\"Confusion Matrix\" if title is None else \"\", fontsize=14)\n",
    "    to_show = plt.imshow(matrix, cmap=\"seismic\")\n",
    "    figure.colorbar(to_show, label=\"Samples\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый класс моделей\n",
    "\n",
    "Воспользуемся полезной техникой из тетради 2. Определим абстрактный базовый класс, который будет\n",
    "описывать устройство модели и сигнатуры её методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBase(ABC):\n",
    "    \"\"\"Base machine learning model class.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.x_train: ndarray\n",
    "        self.y_train: ndarray\n",
    "        basicConfig(format=\"Model: %(message)s\", level=INFO)\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, x_train: ndarray, y_train: ndarray, *args, **kwargs) -> None:\n",
    "        \"\"\"The data passed to this method would be copied and used as\n",
    "        NumPy :class:`ndarray`.\n",
    "        \"\"\"\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, x_test: ndarray) -> Any:\n",
    "        message = \"Every model should implement the `predict()` method\"\n",
    "        raise NotImplementedError(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Образ взаимодействия позаимствован у моделей из Scikit-Learn. В этом фреймворке так же у модели\n",
    "среди прочих есть два основных метода: `fit()` и `predict()`, которые отвечают за процессы обучения\n",
    "и прогнозирования соответсвенно.\n",
    "\n",
    "### Элементарный классификатор\n",
    "\n",
    "На основе `ModelBase` реализуем теперь свой элементарный классификатор. Допустим, есть всего два\n",
    "класса (0 и 1) и один признак. Значения признака могут варьироватся от 0 до 1. Если значение\n",
    "признака больше его стандартного отклонения по обучающим данным, он принадлежит первому классу,\n",
    "если меньше или равно — второму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElementaryClassifier(ModelBase):\n",
    "    # Elementary Classifier inherits from Model Base to provide method\n",
    "    # signatures.\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, x_train: ndarray, y_train: ndarray, *args, **kwargs) -> None:\n",
    "        # This method memorizes the training data and calculates the standard\n",
    "        # deviation of the training features.\n",
    "        super().fit(x_train, y_train)\n",
    "        self.x_train_std = np.std(self.x_train)\n",
    "\n",
    "    def predict(self, x_test: ndarray) -> ndarray:\n",
    "        # This method classifies the data points\n",
    "        pred = list()\n",
    "        for x in x_test:\n",
    "            if x > self.x_train_std:\n",
    "                pred.append(0)\n",
    "            else:\n",
    "                pred.append(1)\n",
    "        pred_arr = np.array(pred)\n",
    "        return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить одну небольшую оптимизацию. Мы всего единажды вычисляем `np.std(self.x_train)`,\n",
    "вместо того, чтобы каждый раз повторять вычисления в цикле в `predict()`. Потом нужно будет лишь\n",
    "сравнить данное число с точкой данных в тестовом наборе. На масштабе такая техника позволяет\n",
    "значительно сократить время прогнозирования.\n",
    "\n",
    "Посмотрим, как наш классификатор отработает на случайных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_features = np.array(random_list(100))\n",
    "fstd = np.std(random_features)\n",
    "classes = np.array([0 if fval > fstd else 1 for fval in random_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудем воспользоваться разделителем данных из первого модуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DataSplitter(permute=True)\n",
    "x_train, x_test, y_train, y_test = splitter.split_data(\n",
    "    random_features, classes, test_size=0.33\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим `ElementaryClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ElementaryClassifier()\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_predicted = classifier.predict(x_test)\n",
    "confusion_matrix = compute_confusion_matrix(\n",
    "    y_test.reshape((-1, 1)), y_predicted.reshape((-1, 1))\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix, \"Elementary Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совсем нетрудно заметить, что наш элементарный классификатор успешно справился со своей задачей.\n",
    "Теперь посмотрим, что будет, если добавить в тестовые данные немного шума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(\n",
    "    [fval + 0.1 if fval < 0.9 else fval for fval in x_test.tolist()]\n",
    ")\n",
    "\n",
    "y_predicted = classifier.predict(x_test)\n",
    "confusion_matrix = compute_confusion_matrix(\n",
    "    y_test.reshape((-1, 1)), y_predicted.reshape((-1, 1))\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix, \"Elementary Classifier with Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо видно, что теперь модель даёт нам 3 ложно отрицательных значений, так как мы изменили\n",
    "тестовый набор, и классы теперь не совсем соответсвуют своим признакам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, имеется три класса, у каждого из которых есть три признака. Значение признака находится в\n",
    "диапазоне от 0 до 1 и является вещественным. Реализуйте модель, которая будет в состоянии присвоить\n",
    "каждой точке данных правильный класс по следующему правилу:\n",
    "- если сумма значений признаков в квадрате больше `1`, но меньше или равна `1.5`, точка относится к\n",
    "первому классу;\n",
    "- если та же сумма больше `1.5`, точка относится ко второму классу;\n",
    "- если эта же сумма меньше или равна `1`, точка относится к третьему классу.\n",
    "\n",
    "Ниже представленны первые 10 строк из набора данных (они уже разделены как нужно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd = np.load(\"data/extremely_complex_data.npy\")\n",
    "\n",
    "splitter = DataSplitter(permute=True)\n",
    "x_train, x_test, y_train, y_test = splitter.split_data(\n",
    "    ecd[:, :3], ecd[:, 3], test_size=0.33\n",
    ")\n",
    "\n",
    "print(\"Extremely complex data:\\n\", ecd[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourExtremelyComplexClassifier(ModelBase): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда реализуете свой классификатор, выполните ячейку ниже, чтобы оценить его работоспособность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = classifier.predict(x_test)\n",
    "confusion_matrix = compute_confusion_matrix(\n",
    "    y_test.reshape((-1, 1)), y_predicted.reshape((-1, 1))\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix, \"Elementary Classifier with Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Классификация — это мощный инструмент машинного обучения, который позволяет решать множество\n",
    "практических задач. Выбор модели зависит от характера данных, объёма выборки и требуемой точности.\n",
    "KNN, несмотря на свою простоту, остаётся популярным методом, особенно для небольших наборов данных\n",
    "и задач, где важна интерпретируемость результатов.\n",
    "\n",
    "В данной тетради мы разобрали устройство базового интерфейса модели и увидили, как и зачем его\n",
    "использовать. А в следующем notebook'е уже намного более подробно будет изучен алгоритм k-ближайших\n",
    "соседей с использованием Евклидова расстояния и взвешивания соседей. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
